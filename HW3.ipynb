{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRJNDGiPU37"
      },
      "source": [
        "## TECHIN 513 - Basic ML\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Install the required packages (scikit-learn, TensorFlow, Keras, PyTorch, and, pandas) if they are not already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JVHNfDPhPjyw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Accuracy: 1.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From c:\\Program Files\\anaconda3\\envs\\env3.11\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Program Files\\anaconda3\\envs\\env3.11\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From c:\\Program Files\\anaconda3\\envs\\env3.11\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Program Files\\anaconda3\\envs\\env3.11\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2558 - accuracy: 0.9261\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1142 - accuracy: 0.9666\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0772 - accuracy: 0.9763\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0584 - accuracy: 0.9819\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0446 - accuracy: 0.9857\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0799 - accuracy: 0.9757\n",
            "Neural Network Test Loss: 0.07992305606603622\n",
            "Neural Network Test Accuracy: 0.9757000207901001\n",
            "Weight: 1.979698896408081\n",
            "Bias: 0.059687793254852295\n"
          ]
        }
      ],
      "source": [
        "# use pip to install the packages\n",
        "# !pip install scikit-learn TensorFlow Keras PyTorch pandas numpy\n",
        "\n",
        "# Import necessary packages\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import RandomForestClassifier from sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Task 1: Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# print(X)\n",
        "\n",
        "# Task 2: Split the data into training and testing sets\n",
        "# use train_test_split function to split the data with test_size = 0.2 and random_state = 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Task 3: Train a Random Forest Classifier on the training data\n",
        "# import RandomForestClassifier from sklearn and fit it with training data\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Task 4: Evaluate the classifier on the testing data\n",
        "# use clf.score function to evaluate the classifier on the testing data\n",
        "# print the accuracy of the classifier\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(\"Random Forest Classifier Accuracy:\", accuracy)\n",
        "\n",
        "# Task 5: Load the MNIST dataset\n",
        "# use keras.datasets.mnist.load_data() to load the dataset\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Task 6: Preprocess the data\n",
        "# normalize the data by dividing by 255.0\n",
        "# use to_categorical from keras.utils to one-hot encode the labels\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Task 7: Define and train a simple neural network using Keras\n",
        "# use Sequential model from keras.models\n",
        "# use Dense layer from keras.layers\n",
        "# use 'adam' as optimizer and 'categorical_crossentropy' as loss function\n",
        "# use model.fit to train the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train.reshape(-1, 784), y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# Task 8: Evaluate the neural network on the testing data\n",
        "# use model.evaluate to get the test loss and test accuracy\n",
        "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 784), y_test)\n",
        "print(\"Neural Network Test Loss:\", test_loss)\n",
        "print(\"Neural Network Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Task 9: Define a simple linear regression model using PyTorch\n",
        "# create a class LinearRegression that inherit from nn.Module\n",
        "# define the constructor and forward function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Task 10: Train the linear regression model on some dummy data and print the weight and bias\n",
        "# create an instance of LinearRegression\n",
        "# use nn.MSELoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias\n",
        "X_train = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y_train = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
        "\n",
        "model = LinearRegression()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Weight:\", model.linear.weight.item())\n",
        "print(\"Bias:\", model.linear.bias.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goIaALYXVy1J"
      },
      "source": [
        "# Bonus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-ZYu5X7gV1L9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.201\n",
            "[1,  4000] loss: 1.901\n",
            "[1,  6000] loss: 1.699\n",
            "[1,  8000] loss: 1.634\n",
            "[1, 10000] loss: 1.549\n",
            "[1, 12000] loss: 1.493\n",
            "[2,  2000] loss: 1.422\n",
            "[2,  4000] loss: 1.409\n",
            "[2,  6000] loss: 1.367\n",
            "[2,  8000] loss: 1.345\n",
            "[2, 10000] loss: 1.314\n",
            "[2, 12000] loss: 1.308\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 53 %\n"
          ]
        }
      ],
      "source": [
        "# Bonus Task: Implement a Convolutional Neural Network to classify the CIFAR-10 dataset\n",
        "# use torchvision.datasets.CIFAR10 to load the dataset\n",
        "# create a class CNN that inherit from nn.Module\n",
        "# define the constructor, forward function and the network architecture\n",
        "# use CrossEntropyLoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "trainset = datasets.CIFAR10(root='C:/Users/Shun-Xi Wu/Downloads/cifar-10-python',\n",
        "                            train=True, download=False, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = datasets.CIFAR10(root='C:/Users/Shun-Xi Wu/Downloads/cifar-10-python',\n",
        "                           train=False, download=False, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        \n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(2):  \n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()  \n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
